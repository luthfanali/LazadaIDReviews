{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ltx/mlops_belajar_step_by_step/03_LazadaIDReviews/LazadaIDReviews/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ltx/mlops_belajar_step_by_step/03_LazadaIDReviews/LazadaIDReviews'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config\n",
    "\n",
    "This code will be apply in `src/LadazaIDReview/entity/config_entity.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataDumpConfig:\n",
    "    root_dir: Path\n",
    "    reviews_path: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    output_train_path: Path\n",
    "    output_test_path: Path\n",
    "    params_test_size: float\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    root_dir: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    vectorized_train_path: Path\n",
    "    vectorized_test_path: Path\n",
    "    model_dir: Path\n",
    "    vectorizer_model_path: Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing Config Manager\n",
    "\n",
    "This code will be apply in `src/LazadaIDReview/config/configurations.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we would do?\n",
    "+ Drop null values\n",
    "+ Splitting the dataset to train and test data\n",
    "+ Vectorize text using `TFIDF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before; letâ€™s load, select columns, and drop null values from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LazadaIDReviews.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LazadaIDReviews.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_dump_data_config(self) -> DataDumpConfig:\n",
    "        \"\"\"read data dump config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        data_ingest_config = self.config.ingest_from_sql\n",
    "        data_dump_config = self.config.dump_data\n",
    "        dataset_params = self.params\n",
    "\n",
    "        create_directories([data_dump_config.root_dir])\n",
    "\n",
    "        config = DataDumpConfig(\n",
    "            root_dir=data_dump_config.root_dir,\n",
    "            reviews_path=data_ingest_config.reviews_path,\n",
    "            input_train_path=data_dump_config.input_train_path,\n",
    "            input_test_path=data_dump_config.input_test_path,\n",
    "            output_train_path=data_dump_config.output_train_path,\n",
    "            output_test_path=data_dump_config.output_test_path,\n",
    "            params_test_size=dataset_params.TEST_SIZE\n",
    "        )\n",
    "\n",
    "        return config\n",
    "    \n",
    "    def get_preprocessing_data_config(self) -> DataPreprocessingConfig:\n",
    "        \"\"\"read preprocessing config file and store as config entity\n",
    "        then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: PreprocessingConfig type\n",
    "        \"\"\"\n",
    "        data_dump_config = self.config.dump_data\n",
    "        vectorize_config = self.config.vectorize_data\n",
    "        train_config = self.config.train_model\n",
    "\n",
    "        create_directories([vectorize_config.root_dir])\n",
    "\n",
    "        config = DataPreprocessingConfig(\n",
    "            root_dir=vectorize_config.root_dir,\n",
    "            input_train_path=Path(data_dump_config.input_train_path),\n",
    "            input_test_path=Path(data_dump_config.input_test_path),\n",
    "            vectorized_train_path=Path(vectorize_config.vectorized_train_path),\n",
    "            vectorized_test_path=Path(vectorize_config.vectorized_test_path),\n",
    "            model_dir=train_config.root_dir,\n",
    "            vectorizer_model_path=Path(vectorize_config.vectorizer_model_path)\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Preprocessing\n",
    "\n",
    "This code in `src/LazadaIDReview/components/preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from LazadaIDReviews import logger\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, config: DataDumpConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def dump_data(self) -> None:\n",
    "        \"\"\"dump the splited dataset to data training and testing\n",
    "        \"\"\"\n",
    "        logger.info(f\"Read reviews file.\")\n",
    "        dataset_reviews = pd.read_csv(self.config.reviews_path)\n",
    "        dataset = dataset_reviews[[\"rating\", \"reviewContent\"]].copy()\n",
    "        dataset.dropna(inplace=True)\n",
    "        \n",
    "        logger.info(f\"Split reviews file to data train and test.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            dataset[\"reviewContent\"], \n",
    "            dataset[\"rating\"], \n",
    "            test_size=self.config.params_test_size\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Dump data train into {self.config.input_train_path} directory.\")\n",
    "        X_train.to_pickle(self.config.input_train_path)\n",
    "        X_test.to_pickle(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Dump data test into {self.config.input_test_path} directory.\")\n",
    "        y_train.to_pickle(self.config.output_train_path)\n",
    "        y_test.to_pickle(self.config.output_test_path)\n",
    "        \n",
    "    def vectorize_data(self) -> None:\n",
    "        \"\"\"vectorize the splited dataset and dump vectorizer model\n",
    "        \"\"\"\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        logger.info(f\"Load data train in {self.config.input_train_path}.\")\n",
    "        X_train = joblib.load(self.config.input_train_path)\n",
    "        \n",
    "        logger.info(f\"Load data test in {self.config.input_test_path}.\")\n",
    "        X_test = joblib.load(self.config.input_test_path)\n",
    "        \n",
    "        logger.info(f\"Vectorize the data.\")\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "        \n",
    "        logger.info(f\"Dump the vectorized data.\")\n",
    "        joblib.dump(X_train_vec, self.config.vectorized_train_path)\n",
    "        joblib.dump(X_test_vec, self.config.vectorized_test_path)\n",
    "        \n",
    "        logger.info(f\"Creating {self.config.model_dir} directory.\")\n",
    "        model_dir = str(self.config.model_dir)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        logger.info(f\"Save the vectorizer model.\")\n",
    "        joblib.dump(vectorizer, self.config.vectorizer_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-10 11:39:16,950: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-10 11:39:16,953: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-10 11:39:16,954: INFO: common: created directory at: artifacts]\n",
      "[2024-07-10 11:39:16,956: INFO: common: created directory at: artifacts/data]\n",
      "[2024-07-10 11:39:16,956: INFO: 944171181: Read reviews file.]\n",
      "[2024-07-10 11:39:17,577: INFO: 944171181: Split reviews file to data train and test.]\n",
      "[2024-07-10 11:39:17,589: INFO: 944171181: Dump data train into artifacts/data/X_train.pkl directory.]\n",
      "[2024-07-10 11:39:17,631: INFO: 944171181: Dump data test into artifacts/data/X_test.pkl directory.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    dump_data_config = config.get_dump_data_config()\n",
    "    data_ingestion = Preprocessing(config=dump_data_config)\n",
    "    data_ingestion.dump_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107181    Paket sy terima sore ini jam 14an, baru sy buk...\n",
       "1140                                       Mkin maju lazada\n",
       "116994    sayang ternyata hddnya belum di partisiðŸ¥ºðŸ¥º tp g...\n",
       "24273     barang sesuai diskripsi, bukan abal abal, semo...\n",
       "200043    Makasih lazada tv nya mantul speakernya jernih...\n",
       "                                ...                        \n",
       "41631     sesuai pesanan packing kayu rapi aman sampe tu...\n",
       "140702                                               mantap\n",
       "35913     salute buat pengirimannya, pagi jam 10 order, ...\n",
       "41009     pacikng rapi, pengiriman cepat dan barangnya b...\n",
       "42572     Kerween tv bagus alhamdulilah dpt harga murmer...\n",
       "Name: reviewContent, Length: 21405, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = joblib.load(dump_data_config.input_train_path)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107181    2\n",
       "1140      5\n",
       "116994    5\n",
       "24273     5\n",
       "200043    5\n",
       "         ..\n",
       "41631     5\n",
       "140702    5\n",
       "35913     5\n",
       "41009     5\n",
       "42572     5\n",
       "Name: rating, Length: 21405, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = joblib.load(dump_data_config.output_train_path)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122876    Sebaiknya penjualan sekaligus dengan windows n...\n",
       "101093    packing bagus..sangat suka. kurir ok/ ninja va...\n",
       "191985                                            mantaplah\n",
       "118565    Untuk produk elektronik packing adalah hal uta...\n",
       "146926    barang datang dengan packing kayu+bubble,setel...\n",
       "                                ...                        \n",
       "120771    Iklan nya Sony kok tampilannya panasonic, yg b...\n",
       "18898                             barang bagus harga miring\n",
       "150708          untuk saat ini aman tidak ada komplain good\n",
       "77962     Lihat dulu ulasan dari pembelian terverifikasi...\n",
       "137785                         Barang sesuai gambar, mantap\n",
       "Name: reviewContent, Length: 85624, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = joblib.load(dump_data_config.input_test_path)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122876    3\n",
       "101093    5\n",
       "191985    5\n",
       "118565    5\n",
       "146926    5\n",
       "         ..\n",
       "120771    3\n",
       "18898     5\n",
       "150708    5\n",
       "77962     1\n",
       "137785    5\n",
       "Name: rating, Length: 85624, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = joblib.load(dump_data_config.output_test_path)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the Data Train and Data Test\n",
    "\n",
    "This code in `src/LazadaIDReview/pipeline/step_02_preprocessing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-10 11:39:27,348: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-10 11:39:27,352: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-10 11:39:27,355: INFO: common: created directory at: artifacts]\n",
      "[2024-07-10 11:39:27,357: INFO: common: created directory at: artifacts/preprocessing]\n",
      "[2024-07-10 11:39:27,361: INFO: 944171181: Load data train in artifacts/data/X_train.pkl.]\n",
      "[2024-07-10 11:39:27,412: INFO: 944171181: Load data test in artifacts/data/X_test.pkl.]\n",
      "[2024-07-10 11:39:27,540: INFO: 944171181: Vectorize the data.]\n",
      "[2024-07-10 11:39:29,008: INFO: 944171181: Dump the vectorized data.]\n",
      "[2024-07-10 11:39:29,031: INFO: 944171181: Creating artifacts/models directory.]\n",
      "[2024-07-10 11:39:29,032: INFO: 944171181: Save the vectorizer model.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    preprocessing_config = config.get_preprocessing_data_config()\n",
    "    preprocessing = Preprocessing(config=preprocessing_config)\n",
    "    preprocessing.vectorize_data()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug**: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21405x13494 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 249818 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec = joblib.load(preprocessing_config.vectorized_train_path)\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85624x13494 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 984966 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec = joblib.load(preprocessing_config.vectorized_test_path)\n",
    "X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_lzd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
